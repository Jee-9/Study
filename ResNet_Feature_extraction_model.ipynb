{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_Feature_extraction_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRWWAvFQwF6q+CaOrNeoz6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jee-9/Study/blob/main/ResNet_Feature_extraction_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq2SVqFkCTeN"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler impoer StepLR\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision import utils\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import copy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "#### download some input Videos - two ways ####\n",
        "import requests\n",
        "\n",
        "from apiclient.discovery import build\n",
        "from apiclient.errors import HttpError\n",
        "from oauth2client.tools import argparser\n",
        "\n",
        "import os\n",
        "import json\n",
        "import urllib\n",
        "import subprocess\n",
        "from pytube import YouTube\n",
        "\n",
        "# download videos using urls\n",
        "link = input(\"Enter the link : \")\n",
        "yt = YouTube(link)\n",
        "\n",
        "print(\"Title:\", yt.title)\n",
        "print(\"Number of views:\", yt.views)\n",
        "print(\"Length of video:\", yt.length, \"seconds\")\n",
        "print(\"Description:\", yt.description)\n",
        "print(\"Ratings\":, yt.rating)\n",
        "\n",
        "# download videos using channel ids\n",
        "DEVELOPER_KEY = \"AIzaSyCuB_gYfkvSA2WKiXjegilvkIfNG5IPpQY\"\n",
        "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
        "YOUTUBE_API_VERSION = \"v3\"\n",
        "\n",
        "class Search_ChannelID:\n",
        "\n",
        "  def __init__(self, username):\n",
        "    self.username = username\n",
        "\n",
        "  def channel_id(self):\n",
        "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=DEVELOPER_KEY)\n",
        "\n",
        "    # call the searched ones.\n",
        "    search_response = youtube.channels().list(part='id',\n",
        "                                              forUsername = str(self.username),\n",
        "                                              maxResults=1).execute()\n",
        "\n",
        "    channelID = {}\n",
        "\n",
        "    search_result = search_response.get(\"items\", [])[0]\n",
        "    if search_result[\"kind\"] == \"youtube#channel\":\n",
        "      channelID[self.username] = search_result[\"id\"]\n",
        "    else:\n",
        "      return \"channel doesn't exist\"\n",
        "\n",
        "    return channelID\n",
        "\n",
        "class Channel():\n",
        "  def __init__(self, channelID):\n",
        "    self.channel = channelID\n",
        "\n",
        "  def youtube_search(self):\n",
        "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=DEVELOPER_KEY)\n",
        "\n",
        "    videos = {}\n",
        "    channels = {}\n",
        "    playlists = {}\n",
        "\n",
        "    for search_result in search_response.get(\"items\", []):\n",
        "      if search_result[\"id\"][\"kind\"] == \"youtube#video\":\n",
        "        videos[search_result[\"snippet\"][\"title\"]] = search_result[\"id\"][\"videoid\"]\n",
        "      elif search_result[\"id\"][\"kind\"] == \"youtube#channel\":\n",
        "        channels[search_result[\"snippet\"][\"title\"]] = search_result[\"id\"][\"channelid\"]\n",
        "      elif search_result[\"id\"][\"kind\"] == \"youtube#playlist\":\n",
        "        playlists[search_result[\"snippet\"][\"title\"]] = search_result[\"id\"][\"playlistid\"]\n",
        "\n",
        "    return videos, channels, playlists\n",
        "\n",
        "\n",
        "link = input(\"Enter the Channel ID:\")\n",
        "vid_num = input(\"Enter the number of vids u want to get:\")\n",
        "ch_id = YouTube(link)\n",
        "ch_cat = Channel(channelID)\n",
        "video_, channels_, playlists_ = mukbang.youtube_search()\n",
        "video_id_list = list(video_.values())\n",
        "\n",
        "for i in range(vid_num):\n",
        "  url = \"https://www.youtube.com/watch?v=\"\n",
        "  video_id = video_id_list[i]\n",
        "  vid_url = url + video_id\n",
        "\n",
        "  yt = YouTube(vid_url)\n",
        "  streams = yt.streams.filter(only_video=True)\n",
        "\n",
        "  for s in streams:\n",
        "    s.download('/content/drive/MyDrive/hw/video') # 영상 다운로드해서 저장  \n",
        "\n",
        "\n",
        "#### SNAPSHOT EXTRACTION ####\n",
        "import matplotlib.pyplot as plt\n",
        "import glob # 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 제시\n",
        "import cv2\n",
        "\n",
        "vid_list = glob.glob('/content/drive/MyDrive/hw/video.*.webm')\n",
        "\n",
        "for idx, vid in enumerate(vid_list):\n",
        "  try:\n",
        "    cap = cv2.VideoCapture(vid_list[idx])\n",
        "\n",
        "    sample_num = 0\n",
        "    captured_num = 0\n",
        "\n",
        "    if not cap.isOpened():\n",
        "      print(\"Cannot open the cap\")\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    while(cap.isOpened()):\n",
        "      ret, frame = cap.read()\n",
        "      sample_num += 1\n",
        "\n",
        "      if not ret:\n",
        "        print(ret)\n",
        "        break\n",
        "\n",
        "      if sample_num == 1800: # 1분에 한개\n",
        "        captured_num += 1\n",
        "        cv2.imwrite('/content/drive/MyDrive/hw/img/' + str(idx) + '_' + str(captured_num) + '.jpg', frame)\n",
        "    cap.release()\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "#### preprocessing the images ####\n",
        "\n",
        "train_transformation = transforms.Compose([transforms.ToTensor(),\n",
        "                                           transforms.Resize((224,224)),\n",
        "                                           transform.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
        "                                           ])\n",
        "\n",
        "dataset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/hw/img', transform = data_transformation)\n",
        "\n",
        "# train_test_split\n",
        "train_size = int(0.8*len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle = True)\n",
        "val_dl = torch.utils.data.DataLoader(val_dataset, batch_size=15, shuffle = True)\n",
        "\n",
        "print(\"Length of dataset:\", len(dataset))\n",
        "print(\"Length of train_dl:\", len(train_dl))\n",
        "print(\"Length of val_dl:\", len(val_dl))\n",
        "\n",
        "print(\"about dataset\")\n",
        "for i, l in dataset:\n",
        "  print(i.shape)\n",
        "  print(l)\n",
        "  break\n",
        "\n",
        "print(\"about train_dl\")\n",
        "for i, l in train_dl:\n",
        "  print(i.shape)\n",
        "  print(l)\n",
        "  break\n",
        "\n",
        "\n",
        "#### MODELING ####\n",
        "\n",
        "class BottleNeck(nn.Module):\n",
        "  expansion = 4 # BottleNeck을 사용하는 50 레이어부터는 * 4 로 채널 올려줌\n",
        "  def __init__(self, in_channels, out_channels, stride=1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.residual_function = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False), # bias = False 주는 이유는 BatchNorm에서 bias 들어가서\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False), ####\n",
        "        # padding=1이 output size = output size 아닌가? 여기 padding = 'same' 안주고 1 주는 이유는 뭘까 ㅠㅠ \n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels * BottleNeck.expansion), # 64 * 4 = 256 , 128 * 4 = 512, 256 * 4 = 1024\n",
        "    )\n",
        "\n",
        "    self.shortcut = nn.Sequential() ## identity shortcut\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    if stride != 1 or in_channels != out_channels * BottleNeck.expansion: ## 가운데 conv2d가 stride != 1이라 변화하지 않는 경우를 말하는 듯\n",
        "      self.shortcut = nn.Sequential(\n",
        "          nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=stride, bias=False), # 위와 같은 경우에는 shortcut 인자에 다음과 같은 연산을 ++++ 해준다\n",
        "          nn.BatchNorm2d(out_channels*BottleNeck.expansion) # BatchNorm 적용 out channels는 X4해서 내보냄.\n",
        "      ) ## projection shortcut\n",
        "      '''\n",
        "      projection shortcut 기법을 사용한 걸로 보이는데 대부분의 경우 identity shortcut보다 projection shortcut 기법을 사용하는 것이 더 정확하지만,\n",
        "      사실 모델의 복잡도가 크게 증가하는 방식이기 때문에 쓰지 않는 경우도 많이 있다고 합니다.\n",
        "      '''\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.residual_function(x) + self.shortcut(x)\n",
        "    x = self.relu(x)\n",
        "    return x\n",
        "\n",
        "#######################################################################################################################################\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, num_block, num_classes=4, init_weights=True): \n",
        "    # init_weights : w의 초기값을 카이밍 히 normalization 사용하겠다는 뜻인거 같음, ResNet에서는 weight initialization 방법으로 he normalization 사용함.\n",
        "    '''\n",
        "    Tensorflow ResNet 모델 구현할 때 \n",
        "      x = Conv2D(filters=filter2, kernel_size=middle_kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base+'2b')(x)\n",
        "      x = BatchNormalization(axis=3, name=bn_name_base+'2b')(x)\n",
        "      x = Activation('relu')(x)\n",
        "    다음과 같이 레이어 쌓는 것과 같은 원리이고 kernel_initializer = 'he_normal'을 여기서는 init_weights로 사용.\n",
        "    '''\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels=64\n",
        "    # 그림 보면 알겠지만 무조건 첫채널 64 !!\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    ) # 여기는 모든 크기의 ResNet에서 공통적인 시작 부분 , kernel_size = 7로 주는 게 특징임.\n",
        "\n",
        "    # Stacking layers\n",
        "    self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
        "    self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
        "    self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
        "    self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
        "\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    if init_weights: # initialize weights : w 초기값 주는 방법\n",
        "      self._initialize_weights()\n",
        "\n",
        "  def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "    strides = [stride] + [1] * (num_blocks-1) # 이거 무슨 문법,,,,? ㅠ\n",
        "    layers=[]\n",
        "    for stride in strides:\n",
        "      layers.append(block(self.in_channels, out_channels, stride))\n",
        "      self.in_channels = out_channels * block.expansion\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.conv1(x)\n",
        "    output = self.conv2_x(output)\n",
        "    x = self.conv3_x(output)\n",
        "    x = self.conv4_x(x)\n",
        "    x = self.conv5_x(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    '''\n",
        "    view 사용문법!\n",
        "    view(-1,3) -> (?,3) 행렬로 바꿔달라.\n",
        "    size(0) -> 행\n",
        "    -> 행 갯수를 그대로 유지하면서 flatten 시키는 건가?\n",
        "    '''\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "  def _initialize_weights(self):\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode = 'fan_out', nonlinearity='relu')\n",
        "        #### init.kaiming_normal_  = he_normalization\n",
        "        if m.bias is not None:\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "      elif isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.constant_(m.weight, 1)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "      elif isinstance(m, nn.Linear):\n",
        "        nn.init.normal_(m.weight, 0, 0.01)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "    # 그러니까 resnet이 weight 처음에 줄 때 카이밍 히 방법을 쓰는 건 알겠는데,,문법이ㅠㅎ (tensorflow에서 'he_normalize' 같은 거인듯) \n",
        "\n",
        "def resnet50():\n",
        "  return ResNet(BottleNeck, [3,4,6,3])\n",
        "\n",
        "def resnet101():\n",
        "  return ResNet(BottleNeck, [3,4,23,3])\n",
        "\n",
        "def resnet152():\n",
        "  return ResNet(BottleNeck, [3,8,36,3])\n",
        "#######################################################################################################################################\n",
        "'''\n",
        "conv2_x\n",
        "conv3_x\n",
        "conv4_x\n",
        "conv5_x 를 지나 마지막에 avg_pool, fc layer를 지나 softmax를 거쳐 num_classes로 분류가 된다.\n",
        "num_classes로 분류가 되기 전에 하나의 레이어를 떼서 값을 벡터화 -> return해주는 모델을 만들어야 함!\n",
        "'''\n",
        "class Feature_extraction(nn.Module):\n",
        "  def __init__(self, block, num_block, init_weights=True): \n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels=64\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    )\n",
        "\n",
        "    # Stacking layers\n",
        "    self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
        "    self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
        "    self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
        "    self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "\n",
        "    if init_weights: \n",
        "      self._initialize_weights()\n",
        "\n",
        "  def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "    strides = [stride] + [1] * (num_blocks-1)\n",
        "    layers=[]\n",
        "    for stride in strides:\n",
        "      layers.append(block(self.in_channels, out_channels, stride))\n",
        "      self.in_channels = out_channels * block.expansion\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.conv1(x)\n",
        "    output = self.conv2_x(output)\n",
        "    x = self.conv3_x(output)\n",
        "    x = self.conv4_x(x)\n",
        "    x = self.conv5_x(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    return x\n",
        "\n",
        "  def _initialize_weights(self):\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode = 'fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "      elif isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.constant_(m.weight, 1)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "      elif isinstance(m, nn.Linear):\n",
        "        nn.init.normal_(m.weight, 0, 0.01)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "\n",
        "def Feature_extraction_50():\n",
        "  return ResNet(BottleNeck, [3,4,6,3])\n",
        "\n",
        "def Feature_extraction_101():\n",
        "  return Feature_extraction(BottleNeck, [3,4,23,3])\n",
        "\n",
        "\n",
        "#### GPU ####\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Feature_extraction_101().to(device)\n",
        "x = torch.randn(3,3,224,224).to(device)\n",
        "output = model(x)\n",
        "print(output.size())\n",
        "\n",
        "# !nvidia-smi \n",
        "\n",
        "summary(model, (3,224,224), device = device.type)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}