{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing_ResNet101.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO21nx4u4KE2Pks9LwnCe24",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jee-9/Study/blob/main/Preprocessing_ResNet101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4dUj1KvcVMp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os \n",
        "from os.path import join\n",
        "\n",
        "\"\"\"## Pytorch를 이용한 이미지 데이터 가져오기\"\"\"\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "import torchvision\n",
        "from torchvision import transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDqYmr6Rcinf",
        "outputId": "cfe4ab26-212b-4a0b-be9c-2a05ca6d34e5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvdNjXa0cgWP"
      },
      "source": [
        "# Base Path 설정\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/PROJECT SHARING FILES\"\n",
        "folder  = \"imageData\"\n",
        "cats = [\"education_images\", \"game_images\", \"kpop_images\", \"mukbang_images\"]\n",
        "\n",
        "for c in cats:\n",
        "  vars()[\"path_\" + c] = join(base_dir, folder, c)\n",
        "\n",
        "root_path = join(base_dir, folder)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKzw_6gict3r"
      },
      "source": [
        "\"\"\"- 일부 이미지 augmentation ( GaussianBlur )\"\"\"\n",
        "\n",
        "blur_trans = transforms.RandomApply([\n",
        "  transforms.GaussianBlur(15)\n",
        "],  p = 0.02)\n",
        "\n",
        "\"\"\"- 일부 이미지 Gaussian Noise 추가하기\"\"\"\n",
        "\n",
        "class AddGaussianNoise(object):\n",
        "  def __init__(self, mean = 0.0, std = 1.0):\n",
        "    self.mean = mean\n",
        "    self.std = std\n",
        "  \n",
        "  def __call__(self, tensor):\n",
        "    return tensor+torch.randn(tensor.size())*self.std+self.mean\n",
        "\n",
        "  def __repr__(self):\n",
        "    return self.__class__.__name__+'(mean={0}, std={1})'.format(self.mean, self,std)\n",
        "\n",
        "noise_trans = transforms.RandomApply([                                   \n",
        "  AddGaussianNoise()\n",
        "], p = 0.02)\n",
        "\n",
        "\"\"\"- 최종 transforms\"\"\"\n",
        "\n",
        "fin_trans = transforms.Compose([transforms.Resize((244,244)), \n",
        "                            blur_trans,\n",
        "                            noise_trans,\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "                            ])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_ml_RQ3c1-0"
      },
      "source": [
        "trainset = torchvision.datasets.ImageFolder(root = root_path,\n",
        "                                            transform = fin_trans)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnGuzfwidcRh"
      },
      "source": [
        "# trainloader = DataLoader(trainset, \n",
        "#                          batch_size = 512,\n",
        "#                          shuffle = True,\n",
        "#                          num_workers = 2)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDPYVsBYeOhg"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM1xpR1Dfj3n"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "from torchvision import utils\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import time\n",
        "import copy\n",
        "import numpy as np"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcRBUZpFeRWT"
      },
      "source": [
        "class BottleNeck(nn.Module):\n",
        "  expansion = 4\n",
        "  def __init__(self, in_channels, out_channels, stride=1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.residual_function = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False), \n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False), \n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels * BottleNeck.expansion), \n",
        "    )\n",
        "\n",
        "    self.shortcut = nn.Sequential()\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    if stride != 1 or in_channels != out_channels * BottleNeck.expansion: \n",
        "      self.shortcut = nn.Sequential(\n",
        "          nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "          nn.BatchNorm2d(out_channels*BottleNeck.expansion) \n",
        "      ) \n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.residual_function(x) + self.shortcut(x)\n",
        "    x = self.relu(x)\n",
        "    return x"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWKO5fEBfiIq"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, num_block, num_classes=4, init_weights = True):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels=64\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    )\n",
        "\n",
        "    # Stacking layers\n",
        "    self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
        "    self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
        "    self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
        "    self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
        "\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    if init_weights:\n",
        "      self._initialize_weights()\n",
        "\n",
        "  def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "    strides = [stride] + [1] * (num_blocks-1)\n",
        "    layers=[]\n",
        "    for stride in strides:\n",
        "      layers.append(block(self.in_channels, out_channels, stride))\n",
        "      self.in_channels = out_channels * block.expansion\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    f_output = self.conv1(x)\n",
        "    output = self.conv2_x(f_output)\n",
        "    x = self.conv3_x(output)\n",
        "    x = self.conv4_x(x)\n",
        "    x = self.conv5_x(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "  def _initialize_weights(self):\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode = 'fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "      elif isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.constant_(m.weight, 1)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "      elif isinstance(m, nn.Linear):\n",
        "        nn.init.normal_(m.weight, 0, 0.01)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "def resnet50():\n",
        "  return ResNet(BottleNeck, [3,4,6,3])\n",
        "\n",
        "def resnet101():\n",
        "  return ResNet(BottleNeck, [3,4,23,3])\n",
        "\n",
        "def resnet152():\n",
        "  return ResNet(BottleNeck, [3,8,36,3])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv2CwqQKkkRa",
        "outputId": "d79eba91-f263-45ed-e2ef-deea596303e6"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = resnet101().to(device)\n",
        "x = torch.randn(3,3,224,224).to(device)\n",
        "output = model(x)\n",
        "print(output.size())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG8Mqfu7kzBY",
        "outputId": "d369a2b5-5208-4d1d-8b1a-bc66358e36f6"
      },
      "source": [
        "summary(model, (3,224,224), device = device.type)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
            "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
            "             ReLU-15          [-1, 256, 56, 56]               0\n",
            "       BottleNeck-16          [-1, 256, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "             ReLU-19           [-1, 64, 56, 56]               0\n",
            "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
            "             ReLU-22           [-1, 64, 56, 56]               0\n",
            "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
            "             ReLU-25          [-1, 256, 56, 56]               0\n",
            "       BottleNeck-26          [-1, 256, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "             ReLU-29           [-1, 64, 56, 56]               0\n",
            "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
            "             ReLU-32           [-1, 64, 56, 56]               0\n",
            "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
            "             ReLU-35          [-1, 256, 56, 56]               0\n",
            "       BottleNeck-36          [-1, 256, 56, 56]               0\n",
            "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
            "             ReLU-39          [-1, 128, 56, 56]               0\n",
            "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
            "             ReLU-42          [-1, 128, 28, 28]               0\n",
            "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-47          [-1, 512, 28, 28]               0\n",
            "       BottleNeck-48          [-1, 512, 28, 28]               0\n",
            "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "             ReLU-51          [-1, 128, 28, 28]               0\n",
            "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "             ReLU-54          [-1, 128, 28, 28]               0\n",
            "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-57          [-1, 512, 28, 28]               0\n",
            "       BottleNeck-58          [-1, 512, 28, 28]               0\n",
            "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
            "             ReLU-61          [-1, 128, 28, 28]               0\n",
            "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
            "             ReLU-64          [-1, 128, 28, 28]               0\n",
            "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-67          [-1, 512, 28, 28]               0\n",
            "       BottleNeck-68          [-1, 512, 28, 28]               0\n",
            "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
            "             ReLU-71          [-1, 128, 28, 28]               0\n",
            "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
            "             ReLU-74          [-1, 128, 28, 28]               0\n",
            "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-77          [-1, 512, 28, 28]               0\n",
            "       BottleNeck-78          [-1, 512, 28, 28]               0\n",
            "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
            "             ReLU-81          [-1, 256, 28, 28]               0\n",
            "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
            "             ReLU-84          [-1, 256, 14, 14]               0\n",
            "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
            "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [-1, 1024, 14, 14]               0\n",
            "       BottleNeck-90         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
            "             ReLU-93          [-1, 256, 14, 14]               0\n",
            "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
            "             ReLU-96          [-1, 256, 14, 14]               0\n",
            "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-99         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-100         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
            "            ReLU-103          [-1, 256, 14, 14]               0\n",
            "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
            "            ReLU-106          [-1, 256, 14, 14]               0\n",
            "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-109         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-110         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
            "            ReLU-113          [-1, 256, 14, 14]               0\n",
            "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
            "            ReLU-116          [-1, 256, 14, 14]               0\n",
            "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-119         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-120         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
            "            ReLU-123          [-1, 256, 14, 14]               0\n",
            "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
            "            ReLU-126          [-1, 256, 14, 14]               0\n",
            "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-129         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-130         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
            "            ReLU-133          [-1, 256, 14, 14]               0\n",
            "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
            "            ReLU-136          [-1, 256, 14, 14]               0\n",
            "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-139         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-140         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-141          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-142          [-1, 256, 14, 14]             512\n",
            "            ReLU-143          [-1, 256, 14, 14]               0\n",
            "          Conv2d-144          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-145          [-1, 256, 14, 14]             512\n",
            "            ReLU-146          [-1, 256, 14, 14]               0\n",
            "          Conv2d-147         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-149         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-150         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-151          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-152          [-1, 256, 14, 14]             512\n",
            "            ReLU-153          [-1, 256, 14, 14]               0\n",
            "          Conv2d-154          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-155          [-1, 256, 14, 14]             512\n",
            "            ReLU-156          [-1, 256, 14, 14]               0\n",
            "          Conv2d-157         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-159         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-160         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-161          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-162          [-1, 256, 14, 14]             512\n",
            "            ReLU-163          [-1, 256, 14, 14]               0\n",
            "          Conv2d-164          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-165          [-1, 256, 14, 14]             512\n",
            "            ReLU-166          [-1, 256, 14, 14]               0\n",
            "          Conv2d-167         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-169         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-170         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-171          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-172          [-1, 256, 14, 14]             512\n",
            "            ReLU-173          [-1, 256, 14, 14]               0\n",
            "          Conv2d-174          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-175          [-1, 256, 14, 14]             512\n",
            "            ReLU-176          [-1, 256, 14, 14]               0\n",
            "          Conv2d-177         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-179         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-180         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-181          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-182          [-1, 256, 14, 14]             512\n",
            "            ReLU-183          [-1, 256, 14, 14]               0\n",
            "          Conv2d-184          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-185          [-1, 256, 14, 14]             512\n",
            "            ReLU-186          [-1, 256, 14, 14]               0\n",
            "          Conv2d-187         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-189         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-190         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-191          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-192          [-1, 256, 14, 14]             512\n",
            "            ReLU-193          [-1, 256, 14, 14]               0\n",
            "          Conv2d-194          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-195          [-1, 256, 14, 14]             512\n",
            "            ReLU-196          [-1, 256, 14, 14]               0\n",
            "          Conv2d-197         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-199         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-200         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-201          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-202          [-1, 256, 14, 14]             512\n",
            "            ReLU-203          [-1, 256, 14, 14]               0\n",
            "          Conv2d-204          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-205          [-1, 256, 14, 14]             512\n",
            "            ReLU-206          [-1, 256, 14, 14]               0\n",
            "          Conv2d-207         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-209         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-210         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-211          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-212          [-1, 256, 14, 14]             512\n",
            "            ReLU-213          [-1, 256, 14, 14]               0\n",
            "          Conv2d-214          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-215          [-1, 256, 14, 14]             512\n",
            "            ReLU-216          [-1, 256, 14, 14]               0\n",
            "          Conv2d-217         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-219         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-220         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-221          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-222          [-1, 256, 14, 14]             512\n",
            "            ReLU-223          [-1, 256, 14, 14]               0\n",
            "          Conv2d-224          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-225          [-1, 256, 14, 14]             512\n",
            "            ReLU-226          [-1, 256, 14, 14]               0\n",
            "          Conv2d-227         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-229         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-230         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-231          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-232          [-1, 256, 14, 14]             512\n",
            "            ReLU-233          [-1, 256, 14, 14]               0\n",
            "          Conv2d-234          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-235          [-1, 256, 14, 14]             512\n",
            "            ReLU-236          [-1, 256, 14, 14]               0\n",
            "          Conv2d-237         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-239         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-240         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-241          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-242          [-1, 256, 14, 14]             512\n",
            "            ReLU-243          [-1, 256, 14, 14]               0\n",
            "          Conv2d-244          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-245          [-1, 256, 14, 14]             512\n",
            "            ReLU-246          [-1, 256, 14, 14]               0\n",
            "          Conv2d-247         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-249         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-250         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-251          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-252          [-1, 256, 14, 14]             512\n",
            "            ReLU-253          [-1, 256, 14, 14]               0\n",
            "          Conv2d-254          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-255          [-1, 256, 14, 14]             512\n",
            "            ReLU-256          [-1, 256, 14, 14]               0\n",
            "          Conv2d-257         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-259         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-260         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-261          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-262          [-1, 256, 14, 14]             512\n",
            "            ReLU-263          [-1, 256, 14, 14]               0\n",
            "          Conv2d-264          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-265          [-1, 256, 14, 14]             512\n",
            "            ReLU-266          [-1, 256, 14, 14]               0\n",
            "          Conv2d-267         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-269         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-270         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-271          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-272          [-1, 256, 14, 14]             512\n",
            "            ReLU-273          [-1, 256, 14, 14]               0\n",
            "          Conv2d-274          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-275          [-1, 256, 14, 14]             512\n",
            "            ReLU-276          [-1, 256, 14, 14]               0\n",
            "          Conv2d-277         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-279         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-280         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-281          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-282          [-1, 256, 14, 14]             512\n",
            "            ReLU-283          [-1, 256, 14, 14]               0\n",
            "          Conv2d-284          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-285          [-1, 256, 14, 14]             512\n",
            "            ReLU-286          [-1, 256, 14, 14]               0\n",
            "          Conv2d-287         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-289         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-290         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-291          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-292          [-1, 256, 14, 14]             512\n",
            "            ReLU-293          [-1, 256, 14, 14]               0\n",
            "          Conv2d-294          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-295          [-1, 256, 14, 14]             512\n",
            "            ReLU-296          [-1, 256, 14, 14]               0\n",
            "          Conv2d-297         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-299         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-300         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-301          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-302          [-1, 256, 14, 14]             512\n",
            "            ReLU-303          [-1, 256, 14, 14]               0\n",
            "          Conv2d-304          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-305          [-1, 256, 14, 14]             512\n",
            "            ReLU-306          [-1, 256, 14, 14]               0\n",
            "          Conv2d-307         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-309         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-310         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-311          [-1, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-313          [-1, 512, 14, 14]               0\n",
            "          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-316            [-1, 512, 7, 7]               0\n",
            "          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n",
            "          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-321           [-1, 2048, 7, 7]               0\n",
            "      BottleNeck-322           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-325            [-1, 512, 7, 7]               0\n",
            "          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-328            [-1, 512, 7, 7]               0\n",
            "          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-331           [-1, 2048, 7, 7]               0\n",
            "      BottleNeck-332           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-335            [-1, 512, 7, 7]               0\n",
            "          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-338            [-1, 512, 7, 7]               0\n",
            "          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-341           [-1, 2048, 7, 7]               0\n",
            "      BottleNeck-342           [-1, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n",
            "          Linear-344                    [-1, 4]           8,196\n",
            "================================================================\n",
            "Total params: 42,508,356\n",
            "Trainable params: 42,508,356\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 429.72\n",
            "Params size (MB): 162.16\n",
            "Estimated Total Size (MB): 592.45\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiuyaXv2k_bO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j8egptSl0yn"
      },
      "source": [
        "# 학습용 함수들"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90TRtJuAl17q"
      },
      "source": [
        "# 손실함수, optimizer, lr_scheduler 정의\n",
        "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
        "opt = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10)\n",
        "\n",
        "# 현재 lr 계산하는 함수\n",
        "def get_lr(opt):\n",
        "  for param_group in opt.param_groups:\n",
        "    return param_group['lr']\n",
        "\n",
        "# 배치당 loss와 metric을 계산하는 함수\n",
        "def metric_per_batch(output, target):\n",
        "  pred = output.argmax(1, keepdim=True)\n",
        "  corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "  return corrects\n",
        "\n",
        "def loss_per_batch(loss_func, output, target, opt=None):\n",
        "  loss = loss_func(output, target)\n",
        "  metric_b = metric_per_batch(output, target)\n",
        "\n",
        "  if opt is not None:\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "  return loss.item(), metric_b\n",
        "\n",
        "# 에폭당 loss를 정의하는 함수\n",
        "def loss_per_epoch(model, loss_func, trainloader, sanity_check=False, opt=None):\n",
        "  running_loss = 0.0\n",
        "  running_metric = 0.0\n",
        "  len_data = len(trainloader.dataset)\n",
        "\n",
        "  for xb, yb in trainloader:\n",
        "    xb = xb.to(device)\n",
        "    yb = yb.to(device)\n",
        "    output = model(xb)\n",
        "\n",
        "    loss_b, metric_b = loss_per_batch(loss_func, output, yb, opt)\n",
        "\n",
        "    running_loss += loss_b\n",
        "\n",
        "    if metric_b is not None:\n",
        "      running_metric += metric_b\n",
        "\n",
        "    if sanity_check is True:\n",
        "      break\n",
        "  loss = running_loss / len_data\n",
        "  metric = running_metric / len_data\n",
        "\n",
        "  return loss, metric"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMenLruPns5-"
      },
      "source": [
        "# 학습함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5hGier8mySs"
      },
      "source": [
        "def train_model(model, params):\n",
        "\n",
        "  num_epochs = params['num_epochs']\n",
        "  loss_func = params['loss_func']\n",
        "  opt = params['optimizer']\n",
        "  trainloader = params['trainloader']\n",
        "  # validationlader = params['validloader']\n",
        "  sanity_check = params['sanity_check']\n",
        "  lr_scheduler = params['lr_scheduler']\n",
        "  path2weights = params['path2weights']\n",
        "\n",
        "  loss_history = {'train': [], 'val' : []}\n",
        "  metric_history = {'train': [], 'val': []}\n",
        "\n",
        "  best_loss = float('inf')\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    current_lr = get_lr(opt)\n",
        "    print('Epoch {}/{}, current lr = {}'.format(epoch, num_epochs-1, current_lr))\n",
        "\n",
        "    model.train()\n",
        "    print('model training finished')\n",
        "\n",
        "    # train_loss, train_metric = loss_per_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
        "    # print('loss_per_epoch finished') \n",
        "    # loss_history['train'].append(train_loss)\n",
        "    # metric_history['train'].append(train_metric)\n",
        "\n",
        "    # model.eval()\n",
        "    # print('model.eval() finished') \n",
        "    # with torch.no_grad():\n",
        "    #   val_loss, val_metric = loss_per_epoch(model, loss_func, validloader, sanity_check)\n",
        "    # loss_history['val'].append(val_loss)\n",
        "    # metric_history['val'].append(val_metric)\n",
        "\n",
        "    # if val_loss < best_loss:\n",
        "    #   best_loss = val_loss\n",
        "    #   # best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    #   # torch.save(model.state_dict(), path2weights)\n",
        "    #   # print('Copied best model weights!')\n",
        "    #   print('Got best val_loss')\n",
        "\n",
        "    # lr_scheduler.step(val_loss)\n",
        "    # # wandb.log({'Epoch': epoch, 'loss': np.mean(loss_arr)}) # 추가된 코드 3\n",
        "    # print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
        "    # print('-'*10)\n",
        "\n",
        "  return model\n",
        "  # , loss_history, metric_history"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72j9NKeopND-"
      },
      "source": [
        "# 하이퍼 파라미터 정의\n",
        "\n",
        "params_train = {\n",
        "    'num_epochs': 90, # 이거 첨에 1000으로 줬는데 아마 오버피팅되었을 가능성이,, ㅎ\n",
        "    'optimizer' : opt,\n",
        "    'loss_func' : loss_func,\n",
        "    'trainloader' : trainloader,\n",
        "    'validloader' : validloader,\n",
        "    'sanity_check' : False,\n",
        "    'lr_scheduler' : lr_scheduler,\n",
        "    'path2weights' : './models/weights.pt',\n",
        "}\n",
        "\n",
        "def createFolder(directory):\n",
        "  try:\n",
        "    if not os.path.exists(directory):\n",
        "      os.makedirs(directory)\n",
        "  except OSerror:\n",
        "    print('Error')\n",
        "\n",
        "createFolder('./models')"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRI9fFy3pOpq",
        "outputId": "406aeffc-c008-4197-a16d-28fc352121ac"
      },
      "source": [
        "# model, loss_hist, metric_hist = train_val(model, params_train)\n",
        "\n",
        "model = train_model(model, params_train)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 1/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 2/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 3/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 4/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 5/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 6/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 7/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 8/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 9/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 10/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 11/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 12/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 13/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 14/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 15/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 16/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 17/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 18/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 19/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 20/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 21/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 22/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 23/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 24/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 25/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 26/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 27/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 28/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 29/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 30/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 31/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 32/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 33/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 34/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 35/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 36/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 37/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 38/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 39/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 40/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 41/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 42/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 43/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 44/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 45/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 46/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 47/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 48/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 49/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 50/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 51/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 52/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 53/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 54/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 55/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 56/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 57/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 58/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 59/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 60/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 61/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 62/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 63/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 64/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 65/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 66/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 67/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 68/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 69/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 70/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 71/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 72/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 73/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 74/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 75/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 76/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 77/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 78/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 79/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 80/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 81/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 82/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 83/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 84/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 85/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 86/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 87/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 88/89, current lr = 0.001\n",
            "model training finished\n",
            "Epoch 89/89, current lr = 0.001\n",
            "model training finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQM1lmkDprmr"
      },
      "source": [
        "# 모델 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcM6Lkohpc1v"
      },
      "source": [
        "# Google drive 에 save\n",
        "model_save_name = 'ResNet101.pt'\n",
        "path = F\"/content/drive/MyDrive/{model_save_name}\"\n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC9hHfNqp7ju"
      },
      "source": [
        "# Google drive에서 load\n",
        "model_save_name = 'ResNet101.pt'\n",
        "path = F\"/content/drive/MyDrive/{model_save_name}\"\n",
        "torch.load_state_dict(torch.load(path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F0GhL9rrgBM"
      },
      "source": [
        "# train_test_split in image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50LU5fpJrRPG"
      },
      "source": [
        "# 1번 방법\n",
        "train_size = int(0.8*len(trainset))\n",
        "test_size = len(trainset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(trainset, [train_size, test_size])\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
        "validloader = torch.utils.data.DataLoader(test_dataset, batch_size=512, shuffle=False)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-pv5iSIwjCy",
        "outputId": "1b5168c1-cb20-4ec6-e5ae-e67f94d6ea71"
      },
      "source": [
        "len(trainloader) # 512*78 = 3만9천9백개 = 거의 4만개"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2i8RJlGwnRZ",
        "outputId": "0f0f1c1c-9a9a-49ce-8842-00e3a9d99c46"
      },
      "source": [
        "len(validloader) # 512*20 = 1만240개 = 1만개 // 도합 5만개 ㅇㅋ"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjTjfqG1rRWe"
      },
      "source": [
        "# 2번 방법\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "batch_size = 512\n",
        "validation_split = .2\n",
        "shuffle_dataset = True\n",
        "random_seed = 42\n",
        "\n",
        "# training, test 분할을 위해 인덱스 생성\n",
        "dataset_size = len(trainset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split*dataset_size))\n",
        "\n",
        "if shuffle_dataset:\n",
        "  np.random.seed(random_seed)\n",
        "  np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "validloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, sampler=valid_sampler)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY_kwu17wqIR",
        "outputId": "2027dbde-aa26-4c18-c148-b833626de41c"
      },
      "source": [
        "len(trainloader)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGyRZwt9wrz1",
        "outputId": "6177b630-c521-4c4a-d8f1-a3795b62428e"
      },
      "source": [
        "len(validloader)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "BDws8ulL0XBI",
        "outputId": "dbb53417-552b-4592-8368-0d263bc3f70d"
      },
      "source": [
        "next(iter(trainloader)) # next만 붙으면 에러가 뜬다."
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-9ac878fc3519>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "id": "X0ondGdmt-tP",
        "outputId": "9ddf04e1-40cf-4e7c-c394-9dc579f97334"
      },
      "source": [
        "# 확인하는 방법이라는데 work XXX\n",
        "\n",
        "inputs, classes = next(iter(trainloader))\n",
        "print(classes)\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "  inpt = inp.numpy().transpose((1,2,0))\n",
        "  mean = np.array([0.5,0.5,0.5])\n",
        "  std = np.array([0.5,0.5,0.5])\n",
        "  inp = std*inp+mean\n",
        "  inp = np.clip(inp, 0 ,1)\n",
        "  plt.imshow(inp)\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.pause(0.001)\n",
        "\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-d1c15ec4695f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 확인하는 방법이라는데 work XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZvLfZlFxEVv"
      },
      "source": [
        "# 이제 split 했으니까 한번 돌려보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udVsxWu0wHmq",
        "outputId": "7a178898-197d-45e8-8e19-4125bcc62496"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2_x): Sequential(\n",
              "    (0): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (conv3_x): Sequential(\n",
              "    (0): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (conv4_x): Sequential(\n",
              "    (0): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (5): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (6): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (7): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (8): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (9): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (10): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (11): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (12): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (13): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (14): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (15): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (16): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (17): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (18): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (19): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (20): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (21): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (22): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (conv5_x): Sequential(\n",
              "    (0): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): BottleNeck(\n",
              "      (residual_function): Sequential(\n",
              "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (shortcut): Sequential()\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ9jjmvXyBtS"
      },
      "source": [
        "def train_model(model, params):\n",
        "\n",
        "  num_epochs = params['num_epochs']\n",
        "  loss_func = params['loss_func']\n",
        "  opt = params['optimizer']\n",
        "  trainloader = params['trainloader']\n",
        "  validloader = params['validloader']\n",
        "  sanity_check = params['sanity_check']\n",
        "  lr_scheduler = params['lr_scheduler']\n",
        "  path2weights = params['path2weights']\n",
        "\n",
        "  loss_history = {'train': [], 'val' : []}\n",
        "  metric_history = {'train': [], 'val': []}\n",
        "\n",
        "  best_loss = float('inf')\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    current_lr = get_lr(opt)\n",
        "    print('Epoch {}/{}, current lr = {}'.format(epoch, num_epochs-1, current_lr))\n",
        "\n",
        "    model.train()\n",
        "    print('model training finished')\n",
        "\n",
        "    train_loss, train_metric = loss_per_epoch(model, loss_func, trainloader, sanity_check, opt)\n",
        "    print('loss_per_epoch finished') \n",
        "    loss_history['train'].append(train_loss)\n",
        "    metric_history['train'].append(train_metric)\n",
        "\n",
        "    model.eval()\n",
        "    print('model.eval() finished') \n",
        "    with torch.no_grad():\n",
        "      val_loss, val_metric = loss_per_epoch(model, loss_func, validloader, sanity_check)\n",
        "    loss_history['val'].append(val_loss)\n",
        "    metric_history['val'].append(val_metric)\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "      best_loss = val_loss\n",
        "      # best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "      # torch.save(model.state_dict(), path2weights)\n",
        "      # print('Copied best model weights!')\n",
        "      print('Got best val_loss')\n",
        "\n",
        "    lr_scheduler.step(val_loss)\n",
        "    # wandb.log({'Epoch': epoch, 'loss': np.mean(loss_arr)}) # 추가된 코드 3\n",
        "    print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
        "    print('-'*10)\n",
        "\n",
        "  return model, loss_history, metric_history"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Wc4w7sZozE01",
        "outputId": "57c32653-c59d-4294-e848-311c33bb103e"
      },
      "source": [
        "model, loss_hist, metric_hist = train_model(model, params_train)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/89, current lr = 0.001\n",
            "model training finished\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-7602a88f89f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-73-f8b7fa515e5d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, params)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model training finished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_per_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanity_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss_per_epoch finished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mloss_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-f56f6e580f31>\u001b[0m in \u001b[0;36mloss_per_epoch\u001b[0;34m(model, loss_func, trainloader, sanity_check, opt)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mlen_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbzlhCXyzJAM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}